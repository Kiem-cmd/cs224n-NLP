{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time \n",
    "import pandas as pd \n",
    "import torch\n",
    "import spacy \n",
    "import torchtext\n",
    "from collections import Counter,OrderedDict \n",
    "from torchtext.data.utils import get_tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/squad/train-v1.1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r', encoding = 'utf-8') as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_data(data):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    print(\"Parsering from json to DataFrame ............\")\n",
    "    start = time.time()\n",
    "    data = data['data'] \n",
    "    qa_list = [] \n",
    "    for paragraphs in data:\n",
    "        for para in paragraphs['paragraphs']:\n",
    "            context = para['context'] \n",
    "            for qa in para['qas']:\n",
    "                id = qa['id'] \n",
    "                question = qa['question']\n",
    "                for ans in qa['answers']:\n",
    "                    answer = ans['text']\n",
    "                    ans_start = ans['answer_start']\n",
    "                    ans_end = ans_start + len(answer)\n",
    "\n",
    "                    qa_dict = dict() \n",
    "                    qa_dict['context'] = context\n",
    "                    qa_dict['question'] = question\n",
    "                    qa_dict['answer'] = answer \n",
    "                    qa_dict['ans_start'] = ans_start \n",
    "                    qa_dict['ans_end'] = ans_end \n",
    "                    qa_list.append(qa_dict) \n",
    "    end = time.time() \n",
    "    print(\"Number of Q/A: \",len(qa_list))\n",
    "    print(f\"Parser data from json to DataFrame in {end- start}s\")\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    return pd.DataFrame(qa_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsering from json to DataFrame ............\n",
      "Number of Q/A:  87599\n",
      "Parser data from json to DataFrame in 0.3076024055480957s\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = parser_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ans_start</th>\n",
       "      <th>ans_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>229</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>Rangoon</td>\n",
       "      <td>414</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>Minsk</td>\n",
       "      <td>476</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>1975</td>\n",
       "      <td>199</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                                        answer  ans_start  ans_end  \n",
       "0                   Saint Bernadette Soubirous        515      541  \n",
       "1                    a copper statue of Christ        188      213  \n",
       "2                            the Main Building        279      296  \n",
       "3      a Marian place of prayer and reflection        381      420  \n",
       "4           a golden statue of the Virgin Mary         92      126  \n",
       "...                                        ...        ...      ...  \n",
       "87594                                   Oregon        229      235  \n",
       "87595                                  Rangoon        414      421  \n",
       "87596                                    Minsk        476      481  \n",
       "87597                                     1975        199      203  \n",
       "87598              Kathmandu Metropolitan City          0       27  \n",
       "\n",
       "[87599 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vocab(data):\n",
    "    ''' \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    print(\"Building text vocab ...............\")\n",
    "    text = [] \n",
    "    total = 0 \n",
    "    start = time.time()\n",
    "    for paragraphs in data:\n",
    "        context_unique = list(paragraphs.context.unique())\n",
    "        question_unique = list(paragraphs.question.unique()) \n",
    "        text.extend(context_unique)\n",
    "        text.extend(question_unique) \n",
    "    print(\"Sum of context + question: \",len(text)) \n",
    "    end = time.time()\n",
    "    print(f\"Build text vocab in {end-start}s\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    return text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building text vocab ...............\n",
      "Sum of context + question:  106246\n",
      "Build text vocab in 0.5262694358825684s\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text_vocab = text2vocab([df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_vocab(vocab_text):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    print(\"Building word vocab ..................\")\n",
    "    start = time.time()\n",
    "    words = []\n",
    "    for seq in vocab_text:\n",
    "        words.extend(tokenizer(seq))\n",
    "    word_counter = Counter(words) \n",
    "    sorted_by_freq = sorted(word_counter.items(), key = lambda x:x[1],reverse=True)\n",
    "    ordered_dict = OrderedDict(sorted_by_freq)\n",
    "    vocab_ = vocab(ordered_dict,specials=['<unk>'])\n",
    "    end = time.time() \n",
    "    print(f\"Len word vocab: {vocab_.__len__()}\")\n",
    "    print(f\"Build word vocab in: {end - start}s\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    return vocab_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building word vocab ..................\n",
      "Len word vocab: 99177\n",
      "Build word vocab in: 10.090356588363647s\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "word_vocab = build_word_vocab(text_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_char_vocab(vocab_text):\n",
    "    ''' \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    print(\"Building char vocab ..........\") \n",
    "    start = time.time() \n",
    "    chars = []\n",
    "    for seq in vocab_text:\n",
    "        for ch in seq:\n",
    "            chars.append(ch) \n",
    "    char_counter = Counter(chars)\n",
    "    sorted_by_freq = sorted(char_counter.items(), key = lambda x:x[1], reverse=True)\n",
    "    ordered_dict = OrderedDict(sorted_by_freq)\n",
    "    vocab_ = vocab(ordered_dict,min_freq=20,specials = ['<unk>','<pad>'])\n",
    "    print(f\"Len char vocab: {vocab_.__len__()}\")\n",
    "    end = time.time()\n",
    "    print(f\"Build char vocab in: {end - start}s\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    return vocab_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building char vocab ..........\n",
      "Len char vocab: 230\n",
      "Build char vocab in: 5.175764083862305s\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "char_vocab = build_char_vocab(text_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pipeline = lambda x: word_vocab(tokenizer(x))\n",
    "char_pipeline = lambda x: char_vocab([i for i in x]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_idx(text,ans_start,ans_end):\n",
    "    current = 0\n",
    "    spans = []\n",
    "    answer_span = []\n",
    "    text = text.replace('\"',\"'\").lower()\n",
    "    tokens = tokenizer(text)\n",
    "    for token in tokens:\n",
    "        current = text.find(token, current)\n",
    "        if current < 0:\n",
    "            print(f\"Token {token} cannot be found\")\n",
    "            raise Exception()\n",
    "        spans.append((current, current + len(token)))\n",
    "        current += len(token)\n",
    "    for idx,span in enumerate(spans):\n",
    "        if not (ans_end <= span[0] or ans_start >= span[1]):\n",
    "            answer_span.append(idx)\n",
    "    y1,y2 = answer_span[0],answer_span[-1]\n",
    "    return (y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [convert_idx(x['context'],x['ans_start'],x['ans_end']) for _,x in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['context_word'] = df['context'].apply(word_pipeline)\n",
    "df['question_word'] = df['question'].apply(word_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ans_start</th>\n",
       "      <th>ans_end</th>\n",
       "      <th>label</th>\n",
       "      <th>context_word</th>\n",
       "      <th>question_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>541</td>\n",
       "      <td>(103, 105)</td>\n",
       "      <td>[15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...</td>\n",
       "      <td>[8, 556, 23, 1, 2718, 745, 6063, 1042, 5, 7784...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>213</td>\n",
       "      <td>(38, 42)</td>\n",
       "      <td>[15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...</td>\n",
       "      <td>[10, 11, 5, 1186, 3, 1, 1092, 1045, 239, 304, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>296</td>\n",
       "      <td>(58, 60)</td>\n",
       "      <td>[15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...</td>\n",
       "      <td>[1, 4208, 3, 1, 3718, 1406, 29, 1092, 1045, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>420</td>\n",
       "      <td>(77, 83)</td>\n",
       "      <td>[15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...</td>\n",
       "      <td>[10, 11, 1, 18370, 29, 1092, 1045, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>126</td>\n",
       "      <td>(18, 24)</td>\n",
       "      <td>[15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...</td>\n",
       "      <td>[10, 8838, 22, 430, 3, 1, 239, 304, 29, 1092, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>229</td>\n",
       "      <td>235</td>\n",
       "      <td>(39, 39)</td>\n",
       "      <td>[1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...</td>\n",
       "      <td>[5, 10, 186, 76, 23, 1500, 41, 1452, 31, 181, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>Rangoon</td>\n",
       "      <td>414</td>\n",
       "      <td>421</td>\n",
       "      <td>(71, 71)</td>\n",
       "      <td>[1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...</td>\n",
       "      <td>[10, 12, 16983, 1022, 89, 14, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>Minsk</td>\n",
       "      <td>476</td>\n",
       "      <td>481</td>\n",
       "      <td>(88, 88)</td>\n",
       "      <td>[1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...</td>\n",
       "      <td>[21, 10, 49088, 49, 55, 1500, 37, 9, 797, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>1975</td>\n",
       "      <td>199</td>\n",
       "      <td>203</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>[1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...</td>\n",
       "      <td>[5, 10, 58, 23, 1500, 701, 44, 1628, 181, 797, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>Kathmandu Metropolitan City</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>[1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...</td>\n",
       "      <td>[10, 11, 27388, 31, 38187, 3, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                                        answer  ans_start  ans_end  \\\n",
       "0                   Saint Bernadette Soubirous        515      541   \n",
       "1                    a copper statue of Christ        188      213   \n",
       "2                            the Main Building        279      296   \n",
       "3      a Marian place of prayer and reflection        381      420   \n",
       "4           a golden statue of the Virgin Mary         92      126   \n",
       "...                                        ...        ...      ...   \n",
       "87594                                   Oregon        229      235   \n",
       "87595                                  Rangoon        414      421   \n",
       "87596                                    Minsk        476      481   \n",
       "87597                                     1975        199      203   \n",
       "87598              Kathmandu Metropolitan City          0       27   \n",
       "\n",
       "            label                                       context_word  \\\n",
       "0      (103, 105)  [15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...   \n",
       "1        (38, 42)  [15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...   \n",
       "2        (58, 60)  [15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...   \n",
       "3        (77, 83)  [15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...   \n",
       "4        (18, 24)  [15185, 2, 1, 131, 38, 9, 545, 744, 4, 7958, 1...   \n",
       "...           ...                                                ...   \n",
       "87594    (39, 39)  [1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...   \n",
       "87595    (71, 71)  [1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...   \n",
       "87596    (88, 88)  [1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...   \n",
       "87597    (32, 32)  [1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...   \n",
       "87598      (0, 2)  [1500, 1174, 49, 20, 27388, 19, 2, 5, 229, 8, ...   \n",
       "\n",
       "                                           question_word  \n",
       "0      [8, 556, 23, 1, 2718, 745, 6063, 1042, 5, 7784...  \n",
       "1       [10, 11, 5, 1186, 3, 1, 1092, 1045, 239, 304, 6]  \n",
       "2      [1, 4208, 3, 1, 3718, 1406, 29, 1092, 1045, 11...  \n",
       "3                  [10, 11, 1, 18370, 29, 1092, 1045, 6]  \n",
       "4      [10, 8838, 22, 430, 3, 1, 239, 304, 29, 1092, ...  \n",
       "...                                                  ...  \n",
       "87594  [5, 10, 186, 76, 23, 1500, 41, 1452, 31, 181, ...  \n",
       "87595                   [10, 12, 16983, 1022, 89, 14, 6]  \n",
       "87596       [21, 10, 49088, 49, 55, 1500, 37, 9, 797, 6]  \n",
       "87597  [5, 10, 58, 23, 1500, 701, 44, 1628, 181, 797, 6]  \n",
       "87598                   [10, 11, 27388, 31, 38187, 3, 6]  \n",
       "\n",
       "[87599 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                                question  \n",
       "0      To whom did the Virgin Mary allegedly appear i...  \n",
       "1      What is in front of the Notre Dame Main Building?  \n",
       "2      The Basilica of the Sacred heart at Notre Dame...  \n",
       "3                      What is the Grotto at Notre Dame?  \n",
       "4      What sits on top of the Main Building at Notre...  \n",
       "...                                                  ...  \n",
       "87594  In what US state did Kathmandu first establish...  \n",
       "87595               What was Yangon previously known as?  \n",
       "87596  With what Belorussian city does Kathmandu have...  \n",
       "87597  In what year did Kathmandu create its initial ...  \n",
       "87598                      What is KMC an initialism of?  \n",
       "\n",
       "[87599 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['context','question']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squad(Dataset):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Squad(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Squad at 0x7f5fcef64750>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(data,batch_size=10,shuffle=False,collate_fn= collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kiem/Github/cs224n-NLP/Lecture 11 QuestionAnswer/BiDAF/data/read_sample_data.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kiem/Github/cs224n-NLP/Lecture%2011%20QuestionAnswer/BiDAF/data/read_sample_data.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i,(data,label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kiem/Github/cs224n-NLP/Lecture%2011%20QuestionAnswer/BiDAF/data/read_sample_data.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kiem/Github/cs224n-NLP/Lecture%2011%20QuestionAnswer/BiDAF/data/read_sample_data.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(label)\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:169\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39m# array of string classes and object\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m np_str_obj_array_pattern\u001b[39m.\u001b[39msearch(elem\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mstr) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem\u001b[39m.\u001b[39mdtype))\n\u001b[1;32m    171\u001b[0m \u001b[39mreturn\u001b[39;00m collate([torch\u001b[39m.\u001b[39mas_tensor(b) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map)\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
     ]
    }
   ],
   "source": [
    "for i,(data,label) in enumerate(train_loader):\n",
    "    print(data)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_char_vector(sentence,max_seq,max_word_ctx): \n",
    "    tokens = tokenizer(sentence)\n",
    "    char_vec = torch.ones(max_seq,max_word_ctx).type(torch.LongTensor)\n",
    "    for i, word in enumerate(tokens):\n",
    "        for j, ch in enumerate(word):\n",
    "            char_vec[i][j] = char_vocab[ch]\n",
    "    return char_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squad():\n",
    "    def __init__(self,data,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        data = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n",
    "        self.data = data \n",
    "        # self.x_train = self.data[['context','question','context_word','question_word']]\n",
    "        # self.y_train = self.data['label']\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,index):\n",
    "        return self.data[index]\n",
    "    def __iter__(self):\n",
    "        for batch in self.data:\n",
    "            max_seq = max([len(ctx) for ctx in batch['context_word']]) \n",
    "            padded_context_word =torch.LongTensor(len(batch),max_seq).fill_(1)\n",
    "            for i,ctx in enumerate(batch['context_word']):\n",
    "                padded_context_word[i,:len(ctx)] = torch.LongTensor(ctx)\n",
    "            max_word_ctx = [[len(i) for i in tokenizer(context)]for context in batch['context']]\n",
    "            max_word_ctx = max([max(i) for i in max_word_ctx])\n",
    "            padded_context_char = torch.ones(len(batch),max_seq,max_word_ctx).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "            for i, context in enumerate(batch['context']):\n",
    "                padded_context_char[i] = make_char_vector(context,max_seq,max_word_ctx) \n",
    "            \n",
    "            max_seq_question = max([len(question) for question in batch['question']]) \n",
    "            padded_question_word = torch.LongTensor(len(batch),max_seq_question).fill_(1)\n",
    "            for i,q in enumerate(batch['question_word']):\n",
    "                padded_question_word[i,:len(q)] = torch.LongTensor(q) \n",
    "            max_word_question = [[len(i) for i in tokenizer(question)] for question in batch['question']]\n",
    "            max_word_question = max([max(i) for i in max_word_question])\n",
    "            padded_question_char = torch.ones(len(batch),max_seq_question,max_word_question).type(torch.LongTensor)\n",
    "            for i,question in enumerate(batch['question']):\n",
    "                padded_question_char[i] = make_char_vector(question,max_seq_question,max_word_question) \n",
    "            \n",
    "            label = torch.LongTensor(list(batch['label']))\n",
    "\n",
    "            yield padded_context_word,padded_context_char,padded_question_word,padded_question_char,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Squad(df,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>ans_start</th>\n",
       "      <th>ans_end</th>\n",
       "      <th>label</th>\n",
       "      <th>context_word</th>\n",
       "      <th>question_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As at most other universities, Notre Dame's st...</td>\n",
       "      <td>How many student news papers are found at Notr...</td>\n",
       "      <td>three</td>\n",
       "      <td>126</td>\n",
       "      <td>131</td>\n",
       "      <td>(24, 24)</td>\n",
       "      <td>[14, 29, 51, 45, 612, 2, 1092, 1045, 13, 16, 3...</td>\n",
       "      <td>[34, 36, 1120, 1109, 3644, 24, 135, 29, 1092, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>As at most other universities, Notre Dame's st...</td>\n",
       "      <td>In what year did the student paper Common Sens...</td>\n",
       "      <td>1987</td>\n",
       "      <td>908</td>\n",
       "      <td>912</td>\n",
       "      <td>(160, 160)</td>\n",
       "      <td>[14, 29, 51, 45, 612, 2, 1092, 1045, 13, 16, 3...</td>\n",
       "      <td>[5, 10, 58, 23, 1, 1120, 782, 185, 1252, 357, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>Where is the headquarters of the Congregation ...</td>\n",
       "      <td>Rome</td>\n",
       "      <td>119</td>\n",
       "      <td>123</td>\n",
       "      <td>(22, 22)</td>\n",
       "      <td>[1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...</td>\n",
       "      <td>[52, 11, 1, 1381, 3, 1, 4569, 3, 1, 1442, 1319...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>What is the primary seminary of the Congregati...</td>\n",
       "      <td>Moreau Seminary</td>\n",
       "      <td>145</td>\n",
       "      <td>160</td>\n",
       "      <td>(29, 30)</td>\n",
       "      <td>[1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...</td>\n",
       "      <td>[10, 11, 1, 483, 6116, 3, 1, 4569, 3, 1, 1442,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>What is the oldest structure at Notre Dame?</td>\n",
       "      <td>Old College</td>\n",
       "      <td>234</td>\n",
       "      <td>245</td>\n",
       "      <td>(47, 48)</td>\n",
       "      <td>[1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...</td>\n",
       "      <td>[10, 11, 1, 871, 732, 29, 1092, 1045, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>What individuals live at Fatima House at Notre...</td>\n",
       "      <td>Retired priests and brothers</td>\n",
       "      <td>356</td>\n",
       "      <td>384</td>\n",
       "      <td>(70, 73)</td>\n",
       "      <td>[1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...</td>\n",
       "      <td>[10, 1069, 358, 29, 27418, 231, 29, 1092, 1045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The university is the major seat of the Congre...</td>\n",
       "      <td>Which prize did Frederick Buechner create?</td>\n",
       "      <td>Buechner Prize for Preaching</td>\n",
       "      <td>675</td>\n",
       "      <td>703</td>\n",
       "      <td>(127, 130)</td>\n",
       "      <td>[1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...</td>\n",
       "      <td>[26, 1935, 23, 2258, 27419, 701, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The College of Engineering was established in ...</td>\n",
       "      <td>How many BS level degrees are offered in the C...</td>\n",
       "      <td>eight</td>\n",
       "      <td>487</td>\n",
       "      <td>492</td>\n",
       "      <td>(79, 79)</td>\n",
       "      <td>[1, 292, 3, 1544, 12, 220, 5, 3366, 2, 121, 2,...</td>\n",
       "      <td>[34, 36, 26068, 469, 1493, 24, 1303, 5, 1, 292...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context  \\\n",
       "8   As at most other universities, Notre Dame's st...   \n",
       "9   As at most other universities, Notre Dame's st...   \n",
       "10  The university is the major seat of the Congre...   \n",
       "11  The university is the major seat of the Congre...   \n",
       "12  The university is the major seat of the Congre...   \n",
       "13  The university is the major seat of the Congre...   \n",
       "14  The university is the major seat of the Congre...   \n",
       "15  The College of Engineering was established in ...   \n",
       "\n",
       "                                             question  \\\n",
       "8   How many student news papers are found at Notr...   \n",
       "9   In what year did the student paper Common Sens...   \n",
       "10  Where is the headquarters of the Congregation ...   \n",
       "11  What is the primary seminary of the Congregati...   \n",
       "12        What is the oldest structure at Notre Dame?   \n",
       "13  What individuals live at Fatima House at Notre...   \n",
       "14         Which prize did Frederick Buechner create?   \n",
       "15  How many BS level degrees are offered in the C...   \n",
       "\n",
       "                          answer  ans_start  ans_end       label  \\\n",
       "8                          three        126      131    (24, 24)   \n",
       "9                           1987        908      912  (160, 160)   \n",
       "10                          Rome        119      123    (22, 22)   \n",
       "11               Moreau Seminary        145      160    (29, 30)   \n",
       "12                   Old College        234      245    (47, 48)   \n",
       "13  Retired priests and brothers        356      384    (70, 73)   \n",
       "14  Buechner Prize for Preaching        675      703  (127, 130)   \n",
       "15                         eight        487      492    (79, 79)   \n",
       "\n",
       "                                         context_word  \\\n",
       "8   [14, 29, 51, 45, 612, 2, 1092, 1045, 13, 16, 3...   \n",
       "9   [14, 29, 51, 45, 612, 2, 1092, 1045, 13, 16, 3...   \n",
       "10  [1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...   \n",
       "11  [1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...   \n",
       "12  [1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...   \n",
       "13  [1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...   \n",
       "14  [1, 110, 11, 1, 123, 2826, 3, 1, 4569, 3, 1442...   \n",
       "15  [1, 292, 3, 1544, 12, 220, 5, 3366, 2, 121, 2,...   \n",
       "\n",
       "                                        question_word  \n",
       "8   [34, 36, 1120, 1109, 3644, 24, 135, 29, 1092, ...  \n",
       "9   [5, 10, 58, 23, 1, 1120, 782, 185, 1252, 357, ...  \n",
       "10  [52, 11, 1, 1381, 3, 1, 4569, 3, 1, 1442, 1319...  \n",
       "11  [10, 11, 1, 483, 6116, 3, 1, 4569, 3, 1, 1442,...  \n",
       "12           [10, 11, 1, 871, 732, 29, 1092, 1045, 6]  \n",
       "13  [10, 1069, 358, 29, 27418, 231, 29, 1092, 1045...  \n",
       "14                [26, 1935, 23, 2258, 27419, 701, 6]  \n",
       "15  [34, 36, 26068, 469, 1493, 24, 1303, 5, 1, 292...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10949.875"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "87599/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10950"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kiem/Github/cs224n-NLP/Lecture 11 QuestionAnswer/BiDAF/data/read_sample_data.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kiem/Github/cs224n-NLP/Lecture%2011%20QuestionAnswer/BiDAF/data/read_sample_data.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kiem/Github/cs224n-NLP/Lecture%2011%20QuestionAnswer/BiDAF/data/read_sample_data.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(i)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kiem/Github/cs224n-NLP/Lecture%2011%20QuestionAnswer/BiDAF/data/read_sample_data.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map)\n\u001b[1;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/anaconda3/envs/env-nlp/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:169\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39m# array of string classes and object\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m np_str_obj_array_pattern\u001b[39m.\u001b[39msearch(elem\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mstr) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem\u001b[39m.\u001b[39mdtype))\n\u001b[1;32m    171\u001b[0m \u001b[39mreturn\u001b[39;00m collate([torch\u001b[39m.\u001b[39mas_tensor(b) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map)\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
